{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T05:54:04.557325Z",
     "start_time": "2018-03-20T05:54:04.547361Z"
    },
    "collapsed": true
   },
   "source": [
    "* Deep Dreaming in Keras.\n",
    "* python deep_dream.py path_to_your_base_image.jpg prefix_for_results\n",
    "* e.g.python deep_dream.py img/mypic.jpg results/dream\n",
    "\n",
    "×　输入图片可以任意大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T05:54:44.348216Z",
     "start_time": "2018-03-20T05:54:15.724999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T06:05:17.380452Z",
     "start_time": "2018-03-20T05:54:44.351363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58875904/58889256 [============================>.] - ETA: 0sModel loaded.\n"
     ]
    }
   ],
   "source": [
    "base_image_path = 'Japanese.jpg'\n",
    "result_prefix = 'results'\n",
    "# dimensions of the generated picture.\n",
    "img_height = 600\n",
    "img_width = 600\n",
    "\n",
    "# some settings we found interesting\n",
    "saved_settings = {\n",
    "    'bad_trip': {'features': {'block4_conv1': 0.05,\n",
    "                              'block4_conv2': 0.01,\n",
    "                              'block4_conv3': 0.01},\n",
    "                 'continuity': 0.1,\n",
    "                 'dream_l2': 0.8,\n",
    "                 'jitter': 5},\n",
    "    'dreamy': {'features': {'block5_conv1': 0.05,\n",
    "                            'block5_conv2': 0.02},\n",
    "               'continuity': 0.1,\n",
    "               'dream_l2': 0.02,\n",
    "               'jitter': 0},\n",
    "}\n",
    "# the settings we will use in this experiment\n",
    "settings = saved_settings['dreamy']\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # util function to open, resize and format pictures\n",
    "    # into appropriate tensors\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # util function to convert a tensor into a valid image\n",
    "    x = x.reshape((img_height, img_width, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "img_size = (img_height, img_width, 3)\n",
    "# this will contain our generated image\n",
    "dream = Input(batch_shape=(1,) + img_size)\n",
    "\n",
    "# build the VGG16 network with our placeholder\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg16.VGG16(input_tensor=dream,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "def continuity_loss(x):\n",
    "    # continuity loss util function\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(x[:, :img_height - 1, :img_width - 1, :] -\n",
    "                     x[:, 1:, :img_width - 1, :])\n",
    "    b = K.square(x[:, :img_height - 1, :img_width - 1, :] -\n",
    "                     x[:, :img_height - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "# define the loss\n",
    "loss = K.variable(0.)\n",
    "for layer_name in settings['features']:\n",
    "    # add the L2 norm of the features of a layer to the loss\n",
    "    assert layer_name in layer_dict.keys(), 'Layer ' + layer_name + ' not found in model.'\n",
    "    coeff = settings['features'][layer_name]\n",
    "    x = layer_dict[layer_name].output\n",
    "    shape = layer_dict[layer_name].output_shape\n",
    "    # we avoid border artifacts by only involving non-border pixels in the loss\n",
    "    loss -= coeff * K.sum(K.square(x[:, 2: shape[1] - 2, 2: shape[2] - 2, :])) / np.prod(shape[1:])\n",
    "# add continuity loss (gives image local coherence, can result in an artful blur)\n",
    "loss += settings['continuity'] * continuity_loss(dream) / np.prod(img_size)\n",
    "# add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)\n",
    "loss += settings['dream_l2'] * K.sum(K.square(dream)) / np.prod(img_size)\n",
    "# feel free to further modify the loss as you see fit, to achieve new effects...\n",
    "# compute the gradients of the dream wrt the loss\n",
    "grads = K.gradients(loss, dream)\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "f_outputs = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1,) + img_size)\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "    \"\"\"Loss and gradients evaluator.This Evaluator class makes it possible to compute loss and gradients in one pass\n",
    "while retrieving them via two separate functions,\"loss\" and \"grads\". This is done because scipy.optimize\n",
    "requires separate functions for loss and gradients,but computing them separately would be inefficient.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T06:16:44.518309Z",
     "start_time": "2018-03-20T06:05:17.383328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 309.912\n",
      "Image saved as results_at_iteration_0.png\n",
      "Iteration 0 completed in 135s\n",
      "Start of iteration 1\n",
      "Current loss value: -332.382\n",
      "Image saved as results_at_iteration_1.png\n",
      "Iteration 1 completed in 136s\n",
      "Start of iteration 2\n",
      "Current loss value: -2028.1\n",
      "Image saved as results_at_iteration_2.png\n",
      "Iteration 2 completed in 147s\n",
      "Start of iteration 3\n",
      "Current loss value: -5442.57\n",
      "Image saved as results_at_iteration_3.png\n",
      "Iteration 3 completed in 128s\n",
      "Start of iteration 4\n",
      "Current loss value: -11045.6\n",
      "Image saved as results_at_iteration_4.png\n",
      "Iteration 4 completed in 139s\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the loss\n",
    "x = preprocess_image(base_image_path)\n",
    "for i in range(5):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    # Add a random jitter to the initial image.\n",
    "    # This will be reverted at decoding time\n",
    "    random_jitter = (settings['jitter'] * 2) * (np.random.random(img_size) - 0.5)\n",
    "    x += random_jitter\n",
    "    # Run L-BFGS for 7 steps\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=7)\n",
    "    print('Current loss value:', min_val)\n",
    "    # Decode the dream and save it\n",
    "    x = x.reshape(img_size)\n",
    "    x -= random_jitter\n",
    "    img = deprocess_image(np.copy(x))\n",
    "    fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

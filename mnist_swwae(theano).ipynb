{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trains a stacked what-where autoencoder built on residual blocks on the NIST dataset.  It exemplifies two influential methods that have been developed\n",
    "in the past few years.The first is the idea of properly 'unpooling.' During any max pool, the\n",
    "exact location (the 'where') of the maximal value in a pooled receptive field\n",
    "is lost, however it can be very useful in the overall reconstruction of an\n",
    "input image.  Therefore, if the 'where' is handed from the encoder\n",
    "to the corresponding decoder layer, features being decoded can be 'placed' in\n",
    "the right location, allowing for reconstructions of much higher fidelity.\n",
    "* References:\n",
    "    [1]'Visualizing and Understanding Convolutional Networks'\n",
    "Matthew D Zeiler, Rob Fergus\n",
    "https://arxiv.org/abs/1311.2901v3\n",
    "\n",
    "    [2]'Stacked What-Where Auto-encoders'\n",
    "Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann LeCun\n",
    "https://arxiv.org/abs/1506.02351v8\n",
    "\n",
    "* The second idea exploited here is that of residual learning.  Residual blocks ease the training process by allowing skip connections that give the network the ability to be as linear (or non-linear) as the data sees fit.  This allows for much deep networks to be easily trained.  The residual element seems to be advantageous in the context of this example as it allows a nice symmetry between the encoder and decoder.  Normally, in the decoder, the final\n",
    "projection to the space where the image is reconstructed is linear, however this does not have to be the case for a residual block as the degree to which its output is linear or non-linear is determined by the data it is fed. However, in order to cap the reconstruction in this example, a hard softmax is applied as a bias because we know the MNIST digits are mapped to [0,1].\n",
    "\n",
    "* References:\n",
    "    [3]\n",
    "    'Deep Residual Learning for Image Recognition'\n",
    "    Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    https://arxiv.org/abs/1512.03385v1\n",
    "\n",
    "    [4]\n",
    "    'Identity Mappings in Deep Residual Networks'\n",
    "    Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    https://arxiv.org/abs/1603.05027v3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, BatchNormalization, ELU\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "\n",
    "def convresblock(x, nfeats=8, ksize=3, nskipped=2, elu=True):\n",
    "    \"\"\"The proposed residual block from [4].\n",
    "\n",
    "    Running with elu=True will use ELU nonlinearity and running with\n",
    "    elu=False will use BatchNorm + RELU nonlinearity.  While ELU's are fast\n",
    "    due to the fact they do not suffer from BatchNorm overhead, they may\n",
    "    overfit because they do not offer the stochastic element of the batch\n",
    "    formation process of BatchNorm, which acts as a good regularizer.\n",
    "\n",
    "    # Arguments\n",
    "        x: 4D tensor, the tensor to feed through the block\n",
    "        nfeats: Integer, number of feature maps for conv layers.\n",
    "        ksize: Integer, width and height of conv kernels in first convolution.\n",
    "        nskipped: Integer, number of conv layers for the residual function.\n",
    "        elu: Boolean, whether to use ELU or BN+RELU.\n",
    "\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, channels, rows, cols)`\n",
    "\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, filters, rows, cols)`\n",
    "    \"\"\"\n",
    "    y0 = Conv2D(nfeats, ksize, padding='same')(x)\n",
    "    y = y0\n",
    "    for i in range(nskipped):\n",
    "        if elu:\n",
    "            y = ELU()(y)\n",
    "        else:\n",
    "            y = BatchNormalization(axis=1)(y)\n",
    "            y = Activation('relu')(y)\n",
    "        y = Conv2D(nfeats, 1, padding='same')(y)\n",
    "    return layers.add([y0, y])\n",
    "\n",
    "\n",
    "def getwhere(x):\n",
    "    ''' Calculate the 'where' mask that contains switches indicating which\n",
    "    index contained the max value when MaxPool2D was applied.  Using the\n",
    "    gradient of the sum is a nice trick to keep everything high level.'''\n",
    "    y_prepool, y_postpool = x\n",
    "    return K.gradients(K.sum(y_postpool), y_prepool)\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    raise RuntimeError('This example can only run with the '\n",
    "                       'Theano backend for the time being, '\n",
    "                       'because it requires taking the gradient '\n",
    "                       'of a gradient, which isn\\'t '\n",
    "                       'supported for all TF ops.')\n",
    "\n",
    "# This example assume 'channels_first' data format.\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# The size of the kernel used for the MaxPooling2D\n",
    "pool_size = 2\n",
    "# The total number of feature maps at each layer\n",
    "nfeats = [8, 16, 32, 64, 128]\n",
    "# The sizes of the pooling kernel at each layer\n",
    "pool_sizes = np.array([1, 1, 1, 1, 1]) * pool_size\n",
    "# The convolution kernel size\n",
    "ksize = 3\n",
    "# Number of epochs to train for\n",
    "epochs = 5\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "if pool_size == 2:\n",
    "    # if using a 5 layer net of pool_size = 2\n",
    "    x_train = np.pad(x_train, [[0, 0], [0, 0], [2, 2], [2, 2]],\n",
    "                     mode='constant')\n",
    "    x_test = np.pad(x_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode='constant')\n",
    "    nlayers = 5\n",
    "elif pool_size == 3:\n",
    "    # if using a 3 layer net of pool_size = 3\n",
    "    x_train = x_train[:, :, :-1, :-1]\n",
    "    x_test = x_test[:, :, :-1, :-1]\n",
    "    nlayers = 3\n",
    "else:\n",
    "    import sys\n",
    "    sys.exit('Script supports pool_size of 2 and 3.')\n",
    "\n",
    "# Shape of input to train on (note that model is fully convolutional however)\n",
    "input_shape = x_train.shape[1:]\n",
    "# The final list of the size of axis=1 for all layers, including input\n",
    "nfeats_all = [input_shape[0]] + nfeats\n",
    "\n",
    "# First build the encoder, all the while keeping track of the 'where' masks\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "# We push the 'where' masks to the following list\n",
    "wheres = [None] * nlayers\n",
    "y = img_input\n",
    "for i in range(nlayers):\n",
    "    y_prepool = convresblock(y, nfeats=nfeats_all[i + 1], ksize=ksize)\n",
    "    y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)\n",
    "    wheres[i] = layers.Lambda(\n",
    "        getwhere, output_shape=lambda x: x[0])([y_prepool, y])\n",
    "\n",
    "# Now build the decoder, and use the stored 'where' masks to place the features\n",
    "for i in range(nlayers):\n",
    "    ind = nlayers - 1 - i\n",
    "    y = UpSampling2D(size=(pool_sizes[ind], pool_sizes[ind]))(y)\n",
    "    y = layers.multiply([y, wheres[ind]])\n",
    "    y = convresblock(y, nfeats=nfeats_all[ind], ksize=ksize)\n",
    "\n",
    "# Use hard_simgoid to clip range of reconstruction\n",
    "y = Activation('hard_sigmoid')(y)\n",
    "\n",
    "# Define the model and it's mean square error loss, and compile it with Adam\n",
    "model = Model(img_input, y)\n",
    "model.compile('adam', 'mse')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, x_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, x_test))\n",
    "\n",
    "# Plot\n",
    "x_recon = model.predict(x_test[:25])\n",
    "x_plot = np.concatenate((x_test[:25], x_recon), axis=1)\n",
    "x_plot = x_plot.reshape((5, 10, input_shape[-2], input_shape[-1]))\n",
    "x_plot = np.vstack([np.hstack(x) for x in x_plot])\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Test Samples: Originals/Reconstructions')\n",
    "plt.imshow(x_plot, interpolation='none', cmap='gray')\n",
    "plt.savefig('reconstructions.png')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
